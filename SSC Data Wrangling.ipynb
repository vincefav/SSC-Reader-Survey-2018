{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slate Star Codex Reader Survey 2018\n",
    "\n",
    "This is the data wrangling notebook to accompany my analysis. It's probably not of interest to you unless a) you're a novice data scientist and want to learn some new stuff, or b) you want to see my methodology to understand the strengths and weaknesses of my approach.\n",
    "\n",
    "TL;DR:\n",
    "\n",
    "- I dummify the multiple choice questions. This means I convert them into multiple yes/no (1/0) questions so we can mathematically analyze them.\n",
    "\n",
    "- For questions that allowed an \"Other\" response, I removed responses that appeared fewer than 3 times, and dummified the rest.\n",
    "\n",
    "- I removed responses that used strings of letters when numbers were expected. For instance, writing \"ten\" instead of \"10.\" This happened often enough that's it's not worth the effort to try fixing them all. We just need a stricter survey next time!\n",
    "\n",
    "- I use machine learning to try predicting missing values. This is largely successful.\n",
    "\n",
    "**If you enjoy this, let's connect on LinkedIn:**\n",
    "\n",
    "**https://www.linkedin.com/in/vincefavilla/**\n",
    "\n",
    "I'm a psychologist and machine learning engineer. Also, I'm in the SF Bay Area and looking for a job outside of academia. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7298, 187)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('ssc2018public_original.xlsx')\n",
    "# data = pd.read_csv('ssc2018public_original.csv', encoding='latin-1', low_memory=False)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open-ended categoricals; people could enter their own text as \"Other\" (bad for data analysis!)\n",
    "# We'll limit them to the most common responses.\n",
    "\n",
    "to_simplify = '''Country\n",
    "State\n",
    "ReligiousDenomination\n",
    "ReligiousBackground\n",
    "PoliticalAffiliation\n",
    "PoliticalChange\n",
    "PoliticalChangeSSC\n",
    "Favoriteblog\n",
    "SSCBenefit\n",
    "SSCChangeMind\n",
    "PoliticalDisagreementI\n",
    "PoliticalDisagreementII'''.split('\\n')\n",
    "\n",
    "# My rule of thumb is \"3 is a pattern.\" So let's remove responses that appear \n",
    "# fewer than 3 times and replace them with \"Other\"\n",
    "for i in to_simplify:\n",
    "    value_counts = data[i].str.lower().value_counts()\n",
    "    value_counts = value_counts[value_counts > 2]\n",
    "    data[i] = np.where(data[i].str.lower().isin(value_counts.index), data[i].str.title(), 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Good categoricals -- need no additional processing\n",
    "to_dummify = '''Race\n",
    "Sex\n",
    "Gender\n",
    "SexualOrientation\n",
    "WorkStatus\n",
    "Profession\n",
    "Degree\n",
    "ReligiousViews\n",
    "ReligiousChange\n",
    "ReligiousChangeII\n",
    "MoralViews\n",
    "LengthofTime\n",
    "AmericanParties\n",
    "PoliticalDisagreementIII\n",
    "TheSystem\n",
    "IncomeStatus\n",
    "IncomeChildhood\n",
    "Cryptocurrency\n",
    "GWWC\n",
    "CharityCareer\n",
    "Depression\n",
    "Anxiety\n",
    "OCD\n",
    "Eatingdisorder\n",
    "Alcoholism\n",
    "Drugaddiction\n",
    "Borderline\n",
    "Bipolar\n",
    "Autism\n",
    "ADHD\n",
    "Schizophrenia\n",
    "Adderall\n",
    "Vegetarian\n",
    "BirthdateEnding\n",
    "Harassment1\n",
    "Harassment2\n",
    "Harassment3\n",
    "Harassment4\n",
    "NaziCategory\n",
    "MarriageCategory\n",
    "Handedness\n",
    "BreatheThrough\n",
    "Placebo\n",
    "PreviousSurveys\n",
    "Mask1\n",
    "Mask2\n",
    "Mask3\n",
    "ParenthesesPalindrome\n",
    "MapRiddle\n",
    "SurgeonRiddle\n",
    "Navon1\n",
    "Navon2\n",
    "Sundown\n",
    "Dancer\n",
    "Dancer2\n",
    "SquaresCircles\n",
    "Tables\n",
    "Cookies\n",
    "Reversal\n",
    "LOC1\n",
    "LOC2\n",
    "LOC3\n",
    "CRTM\n",
    "Wason\n",
    "Referrals\n",
    "PostsRead\n",
    "Comment\n",
    "Subreddit\n",
    "Discord\n",
    "HiddenOpenThreads\n",
    "Meetup\n",
    "PatreonI'''.split('\\n')\n",
    "\n",
    "# Begin dummification!\n",
    "for i in to_dummify:\n",
    "    dums = pd.get_dummies(data[i], prefix=i)\n",
    "    data = pd.concat([data,dums], axis=1)\n",
    "\n",
    "# We've now simplified these, sot they're ready to dummify too.\n",
    "for i in to_simplify:\n",
    "    dums = pd.get_dummies(data[i], prefix=i)\n",
    "    data = pd.concat([data,dums], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       10.0\n",
       "1        2.0\n",
       "2        9.0\n",
       "3        8.0\n",
       "4        NaN\n",
       "5       10.0\n",
       "6        1.0\n",
       "7        2.0\n",
       "8        NaN\n",
       "9        7.0\n",
       "10       1.0\n",
       "11       3.0\n",
       "12       8.0\n",
       "13      10.0\n",
       "14       9.0\n",
       "15       4.0\n",
       "16       8.0\n",
       "17       4.0\n",
       "18      10.0\n",
       "19       5.0\n",
       "20       8.0\n",
       "21       6.0\n",
       "22      10.0\n",
       "23       7.0\n",
       "24       7.0\n",
       "25       NaN\n",
       "26      10.0\n",
       "27       6.0\n",
       "28       7.0\n",
       "29       8.0\n",
       "        ... \n",
       "7268     4.0\n",
       "7269     8.0\n",
       "7270     7.0\n",
       "7271     3.0\n",
       "7272    10.0\n",
       "7273     6.0\n",
       "7274    10.0\n",
       "7275    10.0\n",
       "7276     5.0\n",
       "7277     9.0\n",
       "7278     NaN\n",
       "7279     6.0\n",
       "7280    10.0\n",
       "7281     7.0\n",
       "7282    10.0\n",
       "7283     3.0\n",
       "7284     3.0\n",
       "7285     NaN\n",
       "7286     9.0\n",
       "7287     4.0\n",
       "7288     6.0\n",
       "7289    10.0\n",
       "7290     7.0\n",
       "7291     NaN\n",
       "7292     8.0\n",
       "7293    10.0\n",
       "7294     6.0\n",
       "7295     5.0\n",
       "7296     3.0\n",
       "7297     7.0\n",
       "Name: ChangeOverTenYears, Length: 7298, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ChangeOverTenYears']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I'm going to attempt to turn these questions into numerical scales.\n",
    "# It's not perfect, but I think it's good enough to justify doing.\n",
    "\n",
    "scales = '''Asexuality\n",
    "Relationshipstyle\n",
    "EducationComplete\n",
    "LWID\n",
    "EAID\n",
    "SJID'''.split('\\n')\n",
    "\n",
    "relationship = np.zeros_like(data['Relationshipstyle'])\n",
    "relationship = np.where(data['Relationshipstyle'] == 'Prefer monogamous', 1, relationship)\n",
    "relationship = np.where(data['Relationshipstyle'] == 'Prefer polyamorous', 0, relationship)\n",
    "relationship = np.where(data['Relationshipstyle'] == 'Other', 0.5, relationship)\n",
    "relationship = np.where(data['Relationshipstyle'] == 'Uncertain / no preference', 0.5, relationship)\n",
    "data['Monogamy'] = pd.Series(relationship)\n",
    "\n",
    "data['EducationComplete'] = np.where(data['EducationComplete'] == 'Yes', 1, 0)\n",
    "\n",
    "def yes_no_sorta(col):\n",
    "    new_col = np.zeros_like(data[col])\n",
    "    new_col = np.where(data[col] == 'Yes', 1, new_col)\n",
    "    new_col = np.where(data[col] == 'No', 0, new_col)\n",
    "    new_col = np.where(data[col] == 'Sorta', 0.5, new_col)\n",
    "    return pd.Series(new_col)\n",
    "\n",
    "data['LWID'] = yes_no_sorta('LWID')\n",
    "data['EAID'] = yes_no_sorta('EAID')\n",
    "data['SJID'] = yes_no_sorta('SJID')\n",
    "data['Asexuality'] = yes_no_sorta('Asexuality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Relationship'] = np.where(data['RelationshipStatus'] == 'Single', 0, 1)\n",
    "del data['RelationshipStatus']\n",
    "\n",
    "# I'll make a wild assumption that among people with\n",
    "# 4+ children, the average is 4.5.\n",
    "data['Children'] = data.Children.str.replace(r'4+', '4.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to convert the following columns into numeric values, removing any response that contains non-numeric characters. We're going to lose information the process: imagine someone responding \"about 1400\" vs. \"1400\" for their SAT score; the former is now considered an invalid answer. Due to their sheer amount of data, we have few other options. The survey can be improved next time by forcing numeric responses and instructing people to estimate when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['IQ'] = pd.to_numeric(data['IQ'], errors='coerce')\n",
    "data['Age'] = pd.to_numeric(data['Age'], errors='coerce')\n",
    "data['SATscoresoutof1600'] = pd.to_numeric(data['SATscoresoutof1600'], errors='coerce')\n",
    "data['SATscoresoutof2400'] = pd.to_numeric(data['SATscoresoutof2400'], errors='coerce')\n",
    "data['Income'] = pd.to_numeric(data['Income'], errors='coerce')\n",
    "data['Charity'] = pd.to_numeric(data['Charity'], errors='coerce')\n",
    "data['OlderBrothers'] = pd.to_numeric(data['OlderBrothers'], errors='coerce')\n",
    "data['YoungerBrothers'] = pd.to_numeric(data['YoungerBrothers'], errors='coerce')\n",
    "data['YoungerSisters'] = pd.to_numeric(data['YoungerSisters'], errors='coerce')\n",
    "data['CRT1'] = pd.to_numeric(data['CRT1'], errors='coerce')\n",
    "data['CRT2'] = pd.to_numeric(data['CRT2'], errors='coerce')\n",
    "data['CRT3'] = pd.to_numeric(data['CRT3'], errors='coerce')\n",
    "data['AutismSpectrumTest'] = pd.to_numeric(data['AutismSpectrumTest'], errors='coerce')\n",
    "data['GenderRoleTestM'] = pd.to_numeric(data['GenderRoleTestM'], errors='coerce')\n",
    "data['GenderRoleTestF'] = pd.to_numeric(data['GenderRoleTestF'], errors='coerce')\n",
    "data['Gender2M'] = pd.to_numeric(data['Gender2M'], errors='coerce')\n",
    "data['Gender2F'] = pd.to_numeric(data['Gender2F'], errors='coerce')\n",
    "data['Children'] = pd.to_numeric(data['Children'], errors='coerce')\n",
    "\n",
    "for i in data.columns:\n",
    "    if 'BigFive' in i:\n",
    "        data[i] = pd.to_numeric(data[i], errors='coerce')\n",
    "        data[i] = np.where(data[i] > 100, data[i].mean(), data[i])\n",
    "        data[i] = np.where(data[i] < 0, data[i].mean(), data[i])\n",
    "\n",
    "# This question was reversed, so let's fix it\n",
    "data['GlobalWarming'] = 6 - data['GlobalWarming']\n",
    "\n",
    "# Neuroticism was actually reported as emotional stability, so let's reverse it as well\n",
    "data['BigFiveN'] = 100 - data['BigFiveN']\n",
    "\n",
    "# Combine these two\n",
    "data['State_Washington Dc'] = data['State_Washington Dc'] + data['State_Washington, Dc']\n",
    "del data['State_Washington, Dc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's clean up the data and remove liars and outliers (heh). For the most part, I'm pretty trusting of responses, but just to give you an idea of what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>37.0</td>\n",
       "      <td>M (cisgender)</td>\n",
       "      <td>United States</td>\n",
       "      <td>15000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>24.0</td>\n",
       "      <td>M (cisgender)</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>60000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age         Gender        Country      Income\n",
       "5015  37.0  M (cisgender)  United States  15000000.0\n",
       "6046  24.0  M (cisgender)         Brazil  60000000.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['Income'] > 10000000)][['Age', 'Gender', 'Country', 'Income']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's perfectly reasonable that a 37-year-old American is making \\$15 million a year, but I'm a little skeptical of the 24-year-old Brazilian making \\$60 million. It's not impossible, but it's going to skew our data regardless, so I'm removing him. (If you're the rich Brazilian, drop me a line!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Income less than $60M\n",
    "data = data[(data.Income.isnull()) | (data.Income < 60000000)]\n",
    "\n",
    "# I doubt anyone younger than 12 reads SSC\n",
    "data = data[(data.Age.isnull()) | (data.Age > 11)]\n",
    "\n",
    "# People who entered impossible scores\n",
    "data = data[(data.SATscoresoutof1600.isnull()) | (data.SATscoresoutof1600 <= 1600)]\n",
    "data = data[(data.SATscoresoutof2400.isnull()) | (data.SATscoresoutof2400 <= 2400)]\n",
    "\n",
    "# Some IQ scores seem a liiittle implausible.\n",
    "data = data[(data.IQ.isnull()) | ((data.IQ < 175) & (data.IQ > 70))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I'll be ignoring the following features, either because\n",
    "# they're too open-ended, cause errors, or are too specific to SSC\n",
    "\n",
    "to_delete = '''Adderall4\n",
    "BlogReferrals\n",
    "PostReferrals\n",
    "PatreonII\n",
    "PatreonIII\n",
    "PatreonIV\n",
    "Classified\n",
    "PoliticalChangeDescription\n",
    "SurveyTime\n",
    "Adderall2\n",
    "Adderall3\n",
    "Meetup2\n",
    "Favoriteblog\n",
    "Favoritepost'''.split('\\n')\n",
    "\n",
    "for i in to_delete:\n",
    "    del data[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't always like missing data, so we're going to use some machine learning to infer the missing values. I'll make datasets available both with and without this technique, so you can use whichever version you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SATscoresoutof2400</th>\n",
       "      <td>5785.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChildrenHappiness</th>\n",
       "      <td>5448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IQ</th>\n",
       "      <td>5258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SATscoresoutof1600</th>\n",
       "      <td>4952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnxietyScale</th>\n",
       "      <td>4402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnxietyFIXED</th>\n",
       "      <td>3238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigFiveE</th>\n",
       "      <td>2940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigFiveC</th>\n",
       "      <td>2933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigFiveA</th>\n",
       "      <td>2933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigFiveO</th>\n",
       "      <td>2932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigFiveN</th>\n",
       "      <td>2931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender2M</th>\n",
       "      <td>2814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender2F</th>\n",
       "      <td>2814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenderRoleTestM</th>\n",
       "      <td>2641.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AutismSpectrumTest</th>\n",
       "      <td>2638.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenderRoleTestF</th>\n",
       "      <td>2634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charity</th>\n",
       "      <td>1978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>1739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentile</th>\n",
       "      <td>1506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRT1</th>\n",
       "      <td>1073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRT2</th>\n",
       "      <td>985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRT3</th>\n",
       "      <td>873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaulRyan</th>\n",
       "      <td>796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DetailOriented</th>\n",
       "      <td>716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ThoughtProcess</th>\n",
       "      <td>692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoisyConversations</th>\n",
       "      <td>689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phone</th>\n",
       "      <td>689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NightOwl</th>\n",
       "      <td>688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClothingTags</th>\n",
       "      <td>685.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risks</th>\n",
       "      <td>683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HumanBiodiversity</th>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morality</th>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RomanticLife</th>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BarackObama</th>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rationalistfavorability</th>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aesthetics2</th>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinancialSituation</th>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BasicIncome</th>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arrogance</th>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Immigration</th>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoodScale</th>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocialSkills</th>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChangeOverOneYear</th>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ambition</th>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoliticalSpectrum</th>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feminism</th>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LifeSatisfaction</th>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRisk</th>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trustworthy</th>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DonaldTrump</th>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Puns</th>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Children</th>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GayMarriage</th>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalWarming</th>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSCAgreement</th>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoliticalInterest</th>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSCFavorability</th>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenderConformity</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0\n",
       "SATscoresoutof2400       5785.0\n",
       "ChildrenHappiness        5448.0\n",
       "IQ                       5258.0\n",
       "SATscoresoutof1600       4952.0\n",
       "AnxietyScale             4402.0\n",
       "AnxietyFIXED             3238.0\n",
       "BigFiveE                 2940.0\n",
       "BigFiveC                 2933.0\n",
       "BigFiveA                 2933.0\n",
       "BigFiveO                 2932.0\n",
       "BigFiveN                 2931.0\n",
       "Gender2M                 2814.0\n",
       "Gender2F                 2814.0\n",
       "GenderRoleTestM          2641.0\n",
       "AutismSpectrumTest       2638.0\n",
       "GenderRoleTestF          2634.0\n",
       "Charity                  1978.0\n",
       "Income                   1739.0\n",
       "Percentile               1506.0\n",
       "CRT1                     1073.0\n",
       "CRT2                      985.0\n",
       "CRT3                      873.0\n",
       "PaulRyan                  796.0\n",
       "DetailOriented            716.0\n",
       "ThoughtProcess            692.0\n",
       "NoisyConversations        689.0\n",
       "Phone                     689.0\n",
       "NightOwl                  688.0\n",
       "ClothingTags              685.0\n",
       "Risks                     683.0\n",
       "...                         ...\n",
       "HumanBiodiversity         273.0\n",
       "Status                    265.0\n",
       "Morality                  265.0\n",
       "RomanticLife              246.0\n",
       "BarackObama               225.0\n",
       "Rationalistfavorability   214.0\n",
       "Aesthetics2               212.0\n",
       "FinancialSituation        208.0\n",
       "BasicIncome               204.0\n",
       "Arrogance                 202.0\n",
       "Immigration               196.0\n",
       "MoodScale                 192.0\n",
       "SocialSkills              181.0\n",
       "ChangeOverOneYear         181.0\n",
       "Ambition                  180.0\n",
       "PoliticalSpectrum         180.0\n",
       "Feminism                  178.0\n",
       "LifeSatisfaction          171.0\n",
       "AIRisk                    166.0\n",
       "Trustworthy               162.0\n",
       "DonaldTrump               159.0\n",
       "Puns                      158.0\n",
       "Children                  146.0\n",
       "GayMarriage               145.0\n",
       "GlobalWarming             132.0\n",
       "SSCAgreement               97.0\n",
       "PoliticalInterest          92.0\n",
       "SSCFavorability            62.0\n",
       "Age                        48.0\n",
       "GenderConformity           40.0\n",
       "\n",
       "[81 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.select_dtypes(include=[np.number])\n",
    "data = data.astype(float)\n",
    "data.columns = data.columns.str.replace('[', '(')\n",
    "data.columns = data.columns.str.replace(']', ')')\n",
    "data.columns = data.columns.str.replace('<', 'lessthan')\n",
    "data.to_csv('ssc2018public_cleaned.csv')\n",
    "\n",
    "# Number of missing values per question\n",
    "missing = pd.DataFrame(data.isnull().sum().sort_values(ascending=False))\n",
    "missing[missing > 0].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressing Age with an r2 of 0.699\n",
      "regressing GenderConformity with an r2 of 0.385\n",
      "regressing Children with an r2 of 0.446\n",
      "averaging ChildrenHappiness\n",
      "regressing GenderThoughts with an r2 of 0.26\n",
      "averaging IQ\n",
      "averaging SATscoresoutof1600\n",
      "averaging SATscoresoutof2400\n",
      "averaging Percentile\n",
      "regressing SSCFavorability with an r2 of 0.395\n",
      "regressing SSCAgreement with an r2 of 0.368\n",
      "regressing Rationalistfavorability with an r2 of 0.301\n",
      "regressing PoliticalSpectrum with an r2 of 0.715\n",
      "averaging PoliticalInterest\n",
      "regressing GlobalWarming with an r2 of 0.513\n",
      "regressing Immigration with an r2 of 0.457\n",
      "regressing MinimumWage with an r2 of 0.547\n",
      "regressing GayMarriage with an r2 of 0.506\n",
      "regressing Feminism with an r2 of 0.499\n",
      "regressing HumanBiodiversity with an r2 of 0.312\n",
      "regressing BasicIncome with an r2 of 0.396\n",
      "regressing DonaldTrump with an r2 of 0.509\n",
      "regressing PaulRyan with an r2 of 0.399\n",
      "regressing BarackObama with an r2 of 0.515\n",
      "regressing BernieSanders with an r2 of 0.54\n",
      "averaging Income\n",
      "averaging Charity\n",
      "averaging CharityActivities\n",
      "regressing MoodScale with an r2 of 0.578\n",
      "averaging AnxietyScale\n",
      "regressing LifeSatisfaction with an r2 of 0.679\n",
      "regressing ChangeOverOneYear with an r2 of 0.24\n",
      "regressing ChangeOverTenYears with an r2 of 0.364\n",
      "regressing Ambition with an r2 of 0.352\n",
      "regressing Status with an r2 of 0.411\n",
      "regressing SocialSkills with an r2 of 0.464\n",
      "regressing FinancialSituation with an r2 of 0.437\n",
      "regressing RomanticLife with an r2 of 0.63\n",
      "averaging Morality\n",
      "averaging Trustworthy\n",
      "averaging Puns\n",
      "regressing AIRisk with an r2 of 0.23\n",
      "averaging OlderBrothers\n",
      "averaging YoungerBrothers\n",
      "averaging OlderSisters\n",
      "averaging YoungerSisters\n",
      "averaging Aesthetics1\n",
      "averaging Aesthetics2\n",
      "averaging Arrogance\n",
      "averaging TOA1\n",
      "averaging TOA2\n",
      "regressing TOA3 with an r2 of 0.228\n",
      "regressing TOU1 with an r2 of 0.248\n",
      "regressing TOU2 with an r2 of 0.283\n",
      "regressing TOU3 with an r2 of 0.268\n",
      "regressing TOU4 with an r2 of 0.478\n",
      "regressing TOU5 with an r2 of 0.309\n",
      "regressing ADH1 with an r2 of 0.305\n",
      "averaging TB\n",
      "averaging CRT1\n",
      "averaging CRT2\n",
      "averaging CRT3\n",
      "regressing Risks with an r2 of 0.27\n",
      "averaging Imagination\n",
      "averaging ThoughtProcess\n",
      "averaging NightOwl\n",
      "averaging DetailOriented\n",
      "averaging NoisyConversations\n",
      "averaging Phone\n",
      "averaging ClothingTags\n",
      "regressing AutismSpectrumTest with an r2 of 0.527\n",
      "regressing GenderRoleTestM with an r2 of 0.555\n",
      "regressing GenderRoleTestF with an r2 of 0.535\n",
      "averaging Gender2M\n",
      "regressing Gender2F with an r2 of 0.437\n",
      "regressing BigFiveE with an r2 of 0.533\n",
      "regressing BigFiveN with an r2 of 0.548\n",
      "regressing BigFiveA with an r2 of 0.558\n",
      "regressing BigFiveC with an r2 of 0.267\n",
      "regressing BigFiveO with an r2 of 0.325\n",
      "regressing AnxietyFIXED with an r2 of 0.464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Get null columns\n",
    "null_cols = data.isnull().sum()\n",
    "null_cols = list(null_cols[null_cols != 0].index)\n",
    "\n",
    "for i in null_cols:\n",
    "    x = data.fillna(data.median())\n",
    "    y = x.pop(i)\n",
    "    \n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2)\n",
    "    reg = XGBRegressor()\n",
    "    reg.fit(xtrain, ytrain)      \n",
    "    pred = reg.predict(xtest)\n",
    "    r2 = r2_score(ytest, pred)\n",
    "    \n",
    "    # If we can reasonably predict these values, do so\n",
    "    if r2 > .20:\n",
    "        print('regressing', i, 'with an r2 of', round(r2, 3))\n",
    "        data['predicted'] = reg.predict(data.fillna(data.median()).drop([i], axis=1))\n",
    "        data[i] = np.where(data[i].isnull(), data['predicted'], data[i])\n",
    "        del data['predicted']\n",
    "    \n",
    "    # Otherwise, just take the median\n",
    "    else:\n",
    "        print('averaging', i)\n",
    "        data[i] = data[i].fillna(data[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('ssc2018public_inferred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.IQ.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
